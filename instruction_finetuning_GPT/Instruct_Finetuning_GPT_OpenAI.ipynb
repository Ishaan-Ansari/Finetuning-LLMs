{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073f1ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c95d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ce5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that translates English to French.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate the following English text to French: 'Hello, how are you?'\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dbc4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment ça va ?\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db971f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"fine_tuning_dataset.jsonl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24694551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"How does the `error.tsx` file work in Next.js 13's app directory?\\n\\n###\\n\\n\",\n",
       " 'completion': ' The `error.tsx` is an optional file that isolates the error to the smallest possible subsection of the app. Creating the `error.tsx` file automatically wraps the page inside of a React error boundary. Whenever any error occurs inside the folder where this file is placed, the component will be replaced with the contents of this component. END'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09c6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c1ac959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-GUMubWRvkGBHXBdwi8o7tb', bytes=907788, created_at=1752138920, filename='fine_tuning_dataset.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=open(\"fine_tuning_dataset.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FileObject](data=[FileObject(id='file-GUMubWRvkGBHXBdwi8o7tb', bytes=907788, created_at=1752138920, filename='fine_tuning_dataset.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-4tdHD7VF29pDTX7cKszKEa', bytes=2096642, created_at=1752136706, filename='Think Future_ PNB_SIG Assessment_160625.pdf', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None), FileObject(id='file-FMSzicie5SjwGuaPz7xAMu', bytes=4265, created_at=1734416843, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-KWDYHqgHbwAiiWvin9cQqf', bytes=16752, created_at=1734416842, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-Y6wZgVxhYdARDvit4C9rSN', bytes=4265, created_at=1734411592, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-HqjEQn4NMZ9euC89G86uFX', bytes=16752, created_at=1734411591, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-NmCYXe9pNfSaSgikTe7RXm', bytes=4208, created_at=1734402796, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', expires_at=None, status_details=None), FileObject(id='file-NPZVsvm3XvvDDU7Eqztqy7', bytes=5163, created_at=1734356906, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-8Xzu9kqAvq2QsGPvkLKMsF', bytes=11115, created_at=1734356905, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-8azDWiViB48NxBsTCN4VnJ', bytes=5163, created_at=1734347814, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-XJ5CuPNtUEm4nq2dnhNdEW', bytes=11115, created_at=1734347813, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-lgKHXfgmxlauqYZDtPboO94A', bytes=4224, created_at=1723789926, filename='medConfig.py', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None)], has_more=False, object='list', first_id='file-GUMubWRvkGBHXBdwi8o7tb', last_id='file-lgKHXfgmxlauqYZDtPboO94A')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aef283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = client.files.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb629fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FileObject](data=[FileObject(id='file-GUMubWRvkGBHXBdwi8o7tb', bytes=907788, created_at=1752138920, filename='fine_tuning_dataset.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-4tdHD7VF29pDTX7cKszKEa', bytes=2096642, created_at=1752136706, filename='Think Future_ PNB_SIG Assessment_160625.pdf', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None), FileObject(id='file-FMSzicie5SjwGuaPz7xAMu', bytes=4265, created_at=1734416843, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-KWDYHqgHbwAiiWvin9cQqf', bytes=16752, created_at=1734416842, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-Y6wZgVxhYdARDvit4C9rSN', bytes=4265, created_at=1734411592, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-HqjEQn4NMZ9euC89G86uFX', bytes=16752, created_at=1734411591, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-NmCYXe9pNfSaSgikTe7RXm', bytes=4208, created_at=1734402796, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', expires_at=None, status_details=None), FileObject(id='file-NPZVsvm3XvvDDU7Eqztqy7', bytes=5163, created_at=1734356906, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-8Xzu9kqAvq2QsGPvkLKMsF', bytes=11115, created_at=1734356905, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-8azDWiViB48NxBsTCN4VnJ', bytes=5163, created_at=1734347814, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-XJ5CuPNtUEm4nq2dnhNdEW', bytes=11115, created_at=1734347813, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None), FileObject(id='file-lgKHXfgmxlauqYZDtPboO94A', bytes=4224, created_at=1723789926, filename='medConfig.py', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None)], has_more=False, object='list', first_id='file-GUMubWRvkGBHXBdwi8o7tb', last_id='file-lgKHXfgmxlauqYZDtPboO94A')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0b13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-GUMubWRvkGBHXBdwi8o7tb\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-GUMubWRvkGBHXBdwi8o7tb', bytes=907788, created_at=1752138920, filename='fine_tuning_dataset.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-4tdHD7VF29pDTX7cKszKEa\n",
      "assistants\n",
      "====================================================================================================\n",
      "FileObject(id='file-4tdHD7VF29pDTX7cKszKEa', bytes=2096642, created_at=1752136706, filename='Think Future_ PNB_SIG Assessment_160625.pdf', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None)\n",
      "file-FMSzicie5SjwGuaPz7xAMu\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-FMSzicie5SjwGuaPz7xAMu', bytes=4265, created_at=1734416843, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-KWDYHqgHbwAiiWvin9cQqf\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-KWDYHqgHbwAiiWvin9cQqf', bytes=16752, created_at=1734416842, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-Y6wZgVxhYdARDvit4C9rSN\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-Y6wZgVxhYdARDvit4C9rSN', bytes=4265, created_at=1734411592, filename='fine_tuning_validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-HqjEQn4NMZ9euC89G86uFX\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-HqjEQn4NMZ9euC89G86uFX', bytes=16752, created_at=1734411591, filename='fine_tuning_training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-NmCYXe9pNfSaSgikTe7RXm\n",
      "fine-tune-results\n",
      "====================================================================================================\n",
      "FileObject(id='file-NmCYXe9pNfSaSgikTe7RXm', bytes=4208, created_at=1734402796, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', expires_at=None, status_details=None)\n",
      "file-NPZVsvm3XvvDDU7Eqztqy7\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-NPZVsvm3XvvDDU7Eqztqy7', bytes=5163, created_at=1734356906, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-8Xzu9kqAvq2QsGPvkLKMsF\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-8Xzu9kqAvq2QsGPvkLKMsF', bytes=11115, created_at=1734356905, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-8azDWiViB48NxBsTCN4VnJ\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-8azDWiViB48NxBsTCN4VnJ', bytes=5163, created_at=1734347814, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-XJ5CuPNtUEm4nq2dnhNdEW\n",
      "fine-tune\n",
      "====================================================================================================\n",
      "FileObject(id='file-XJ5CuPNtUEm4nq2dnhNdEW', bytes=11115, created_at=1734347813, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n",
      "file-lgKHXfgmxlauqYZDtPboO94A\n",
      "assistants\n",
      "====================================================================================================\n",
      "FileObject(id='file-lgKHXfgmxlauqYZDtPboO94A', bytes=4224, created_at=1723789926, filename='medConfig.py', object='file', purpose='assistants', status='processed', expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file.id)\n",
    "    print(file.purpose)\n",
    "    print(100*\"=\")\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "824ebf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_id = \"file-GUMubWRvkGBHXBdwi8o7tb\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c30a4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_name=\"finetune model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6785c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-QnM1VUn5yVELY9G7MUEUYCNK', created_at=1752139163, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1613016796, status='validating_files', trained_tokens=None, training_file='file-GUMubWRvkGBHXBdwi8o7tb', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'))), user_provided_suffix='finetune model', usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7309cd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-QnM1VUn5yVELY9G7MUEUYCNK', created_at=1752139163, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1613016796, status='validating_files', trained_tokens=None, training_file='file-GUMubWRvkGBHXBdwi8o7tb', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'))), user_provided_suffix='finetune model', usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-1calbtCQAWf9KG9qIiQSn1Cd', created_at=1734416997, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-KWDYHqgHbwAiiWvin9cQqf is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=748458094, status='failed', trained_tokens=None, training_file='file-KWDYHqgHbwAiiWvin9cQqf', validation_file='file-FMSzicie5SjwGuaPz7xAMu', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-JF7lHFkTxG0aU7bJwyZEOSVo', created_at=1734416884, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-KWDYHqgHbwAiiWvin9cQqf is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1304813948, status='failed', trained_tokens=None, training_file='file-KWDYHqgHbwAiiWvin9cQqf', validation_file='file-FMSzicie5SjwGuaPz7xAMu', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-PG3KzfkvehsAzygS8DcsgBIV', created_at=1734411672, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-HqjEQn4NMZ9euC89G86uFX is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=932223364, status='failed', trained_tokens=None, training_file='file-HqjEQn4NMZ9euC89G86uFX', validation_file='file-Y6wZgVxhYdARDvit4C9rSN', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-dQOxFlauWHnWX8dkVl3N1QYr', created_at=1734411630, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-HqjEQn4NMZ9euC89G86uFX is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1401466282, status='failed', trained_tokens=None, training_file='file-HqjEQn4NMZ9euC89G86uFX', validation_file='file-Y6wZgVxhYdARDvit4C9rSN', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-e8sgKgFakBN2LQfrvPgEHgyt', created_at=1734402098, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j', finished_at=1734402793, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=['file-NmCYXe9pNfSaSgikTe7RXm'], seed=1129372722, status='succeeded', trained_tokens=11185, training_file='file-8Xzu9kqAvq2QsGPvkLKMsF', validation_file='file-NPZVsvm3XvvDDU7Eqztqy7', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-Ktt2AZZkSOE6qMRsskXnQbWk', created_at=1734356913, error=Error(code='server_error', message='The job failed due to an internal error.', param=None), fine_tuned_model=None, finished_at=1734365029, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1739908688, status='failed', trained_tokens=None, training_file='file-8Xzu9kqAvq2QsGPvkLKMsF', validation_file='file-NPZVsvm3XvvDDU7Eqztqy7', estimated_finish=1752139414, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None), FineTuningJob(id='ftjob-9B9ydUftravlMlJ9bAW8U3Sh', created_at=1734347841, error=Error(code='server_error', message='The job failed due to an internal error.', param=None), fine_tuned_model=None, finished_at=1734355841, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=2024423889, status='failed', trained_tokens=None, training_file='file-XJ5CuPNtUEm4nq2dnhNdEW', validation_file='file-8azDWiViB48NxBsTCN4VnJ', estimated_finish=1752139484, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)], has_more=False, object='list')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce811b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-QnM1VUn5yVELY9G7MUEUYCNK\n",
      "failed\n",
      "1752139163\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-QnM1VUn5yVELY9G7MUEUYCNK', created_at=1752139163, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Example 1 is missing key \"messages\".', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1613016796, status='failed', trained_tokens=None, training_file='file-GUMubWRvkGBHXBdwi8o7tb', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'))), user_provided_suffix='finetune model', usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-1calbtCQAWf9KG9qIiQSn1Cd\n",
      "failed\n",
      "1734416997\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-1calbtCQAWf9KG9qIiQSn1Cd', created_at=1734416997, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-KWDYHqgHbwAiiWvin9cQqf is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=748458094, status='failed', trained_tokens=None, training_file='file-KWDYHqgHbwAiiWvin9cQqf', validation_file='file-FMSzicie5SjwGuaPz7xAMu', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-JF7lHFkTxG0aU7bJwyZEOSVo\n",
      "failed\n",
      "1734416884\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-JF7lHFkTxG0aU7bJwyZEOSVo', created_at=1734416884, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-KWDYHqgHbwAiiWvin9cQqf is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1304813948, status='failed', trained_tokens=None, training_file='file-KWDYHqgHbwAiiWvin9cQqf', validation_file='file-FMSzicie5SjwGuaPz7xAMu', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-PG3KzfkvehsAzygS8DcsgBIV\n",
      "failed\n",
      "1734411672\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-PG3KzfkvehsAzygS8DcsgBIV', created_at=1734411672, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-HqjEQn4NMZ9euC89G86uFX is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=932223364, status='failed', trained_tokens=None, training_file='file-HqjEQn4NMZ9euC89G86uFX', validation_file='file-Y6wZgVxhYdARDvit4C9rSN', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-dQOxFlauWHnWX8dkVl3N1QYr\n",
      "failed\n",
      "1734411630\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-dQOxFlauWHnWX8dkVl3N1QYr', created_at=1734411630, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-HqjEQn4NMZ9euC89G86uFX is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1401466282, status='failed', trained_tokens=None, training_file='file-HqjEQn4NMZ9euC89G86uFX', validation_file='file-Y6wZgVxhYdARDvit4C9rSN', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-e8sgKgFakBN2LQfrvPgEHgyt\n",
      "succeeded\n",
      "1734402098\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-e8sgKgFakBN2LQfrvPgEHgyt', created_at=1734402098, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j', finished_at=1734402793, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=['file-NmCYXe9pNfSaSgikTe7RXm'], seed=1129372722, status='succeeded', trained_tokens=11185, training_file='file-8Xzu9kqAvq2QsGPvkLKMsF', validation_file='file-NPZVsvm3XvvDDU7Eqztqy7', estimated_finish=None, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-Ktt2AZZkSOE6qMRsskXnQbWk\n",
      "failed\n",
      "1734356913\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-Ktt2AZZkSOE6qMRsskXnQbWk', created_at=1734356913, error=Error(code='server_error', message='The job failed due to an internal error.', param=None), fine_tuned_model=None, finished_at=1734365029, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=1739908688, status='failed', trained_tokens=None, training_file='file-8Xzu9kqAvq2QsGPvkLKMsF', validation_file='file-NPZVsvm3XvvDDU7Eqztqy7', estimated_finish=1752139436, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n",
      "ftjob-9B9ydUftravlMlJ9bAW8U3Sh\n",
      "failed\n",
      "1734347841\n",
      "====================================================================================================\n",
      "FineTuningJob(id='ftjob-9B9ydUftravlMlJ9bAW8U3Sh', created_at=1734347841, error=Error(code='server_error', message='The job failed due to an internal error.', param=None), fine_tuned_model=None, finished_at=1734355841, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=1.8, n_epochs=5), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-ritf6IvNEIMLbJ305TmgRjHR', result_files=[], seed=2024423889, status='failed', trained_tokens=None, training_file='file-XJ5CuPNtUEm4nq2dnhNdEW', validation_file='file-8azDWiViB48NxBsTCN4VnJ', estimated_finish=1752139506, integrations=[], metadata=None, method=None, user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)\n"
     ]
    }
   ],
   "source": [
    "for job in client.fine_tuning.jobs.list():\n",
    "    print(job.id)\n",
    "    print(job.status)\n",
    "    print(job.created_at)\n",
    "    print(100*\"=\")\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54a585ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for job in client.fine_tuning.jobs.list():\n",
    "    print(job.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c8aca0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Brhox7RnFxZfxb8VYgiBLLObqPuSx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sure! Let’s break down the concept of low-rank adaptation (LoRA) in neural networks step by step.\\n\\n### Step 1: Understanding Neural Networks\\n- **Neural Networks**: Imagine a neural network as a complex function that takes input data (like images or text) and transforms it into output (like predictions or classifications).\\n- **Weights**: These networks learn by adjusting parameters called weights, which determine how input data is processed.\\n\\n### Step 2: The Challenge of Fine-tuning\\n- **Fine-tuning**: When we want to adapt a pre-trained model (a model that has already learned from a large dataset) to a specific task (like translating text), we typically fine-tune it by further training.\\n- **Problem**: This process can consume a lot of computational resources, and it requires storing many parameters, which can be inefficient, especially for large models.\\n\\n### Step 3: Understanding Rank in Matrices\\n- **Matrices**: In the context of neural networks, weights can be understood as matrices (think of a grid of numbers that help the network make decisions).\\n- **Rank**: The rank of a matrix refers to the number of independent rows or columns it has. A **low-rank** matrix is one where most of its dimensions are dependent on a smaller number of dimensions.\\n\\n### Step 4: The Intuition Behind Low-Rank Adaptation (LoRA)\\n- **Targeting Efficiency**: LoRA proposes that when we want to adapt a model to a new task, we don’t need to change all of the parameters in the weight matrix. Instead, we can make targeted changes that capture the essence of the new task.\\n- **Low-Rank Matrices for Adaptation**: LoRA achieves this by introducing low-rank matrices to represent the changes needed for adaptation. Instead of modifying the full weight matrix directly, it adds a pair of low-rank matrices (let's call them A and B) that adjust the existing weights. \\n\\n### Step 5: How LoRA Works in Practice\\n1. **Identify the Pre-trained Model**: Start with a model that's already been trained on a large dataset.\\n2. **Introduce Low-Rank Matrices**: To adapt this model for a specific task, LoRA incorporates these low-rank matrices into the existing architecture, effectively allowing the model to adjust without retraining everything.\\n3. **Train the Low-Rank Adjustments**: Only the parameters in these low-rank matrices A and B are fine-tuned during the training on the new dataset.\\n\\n### Step 6: Benefits of LoRA\\n- **Efficiency**: LoRA dramatically reduces the amount of computation and data that needs to be manipulated while maintaining performance. You don't have to fine-tune all parameters, which saves time and computational power.\\n- **Storage Savings**: It also occupies less storage space because you're only adding small matrices instead of modifying all the weights in the model.\\n\\n### Conclusion\\nLow-rank adaptation (LoRA) allows us to effectively and efficiently fine-tune pre-trained neural networks for specific tasks by introducing low-rank adjustments instead of retraining the entire model. This not only conserves computational resources but also streamlines the adaptation process.\\n\\nIn simple terms, think of it as making small, smart adjustments to a well-tuned instrument rather than trying to start from scratch each time you want to play a new song.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1752139531, model='ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j', object='chat.completion', service_tier='default', system_fingerprint='fp_6bf4eada53', usage=CompletionUsage(completion_tokens=692, prompt_tokens=43, total_tokens=735, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful technical tutor. Explain concepts in simple terms.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the intuition behind low‑rank adaptation (LoRA) in neural networks, step by step\",\n",
    "        },\n",
    "    ],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9ea25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-mini-2024-07-18:personal::AfHgZp7j\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful technical tutor. Explain concepts in simple terms.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the intuition behind Quantized low‑rank adaptation (QLoRA) in neural networks, step by step\",\n",
    "        },\n",
    "    ],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c389ddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's break down the concept of Quantized Low-Rank Adaptation (QLoRA) step by step, so it’s easy to understand.\n",
      "\n",
      "### Step 1: Understanding Neural Networks\n",
      "Neural networks are machine learning models that learn to perform tasks, like recognizing images or generating text. They consist of layers of interconnected nodes (neurons), which process and transform input data.\n",
      "\n",
      "### Step 2: Fine-tuning Neural Networks\n",
      "When we want to adapt a large pre-trained neural network for a specific task, we often perform a process called fine-tuning. This involves retraining the model on a smaller, task-specific dataset. Fine-tuning allows the model to leverage its existing knowledge while becoming specialized for the new task.\n",
      "\n",
      "### Step 3: Challenges of Fine-tuning\n",
      "Fine-tuning large models can be resource-intensive. These models require a lot of memory and processing power, making it challenging to deploy them on devices with limited resources. This is where techniques like parameter-efficient tuning come into play.\n",
      "\n",
      "### Step 4: Low-Rank Adaptation (LoRA)\n",
      "Low-Rank Adaptation (LoRA) is one such technique. Instead of updating all the parameters of a neural network during fine-tuning, LoRA introduces a smaller number of additional parameters that can capture the necessary adjustments. In simple terms, it modifies only a \"low-rank\" set of parameters, making the fine-tuning process more efficient.\n",
      "\n",
      "### Step 5: Introducing Quantization\n",
      "Quantization is another technique used to reduce the size of models. Instead of using high-precision floating-point numbers (which can be large and take up a lot of space), quantization reduces the precision of the numbers used in the model's calculations. This significantly decreases the model’s size and the computational resources required, making it easier to run on edge devices.\n",
      "\n",
      "### Step 6: Combining LoRA and Quantization\n",
      "QLoRA combines these two methods: low-rank adaptation and quantization. It fine-tunes a model efficiently by only adjusting a small set of low-rank parameters and then quantizing these adjusted parameters to save space.\n",
      "\n",
      "### Step 7: The Benefits of QLoRA\n",
      "The primary benefits of QLoRA are:\n",
      "- **Efficiency**: It requires less computational power compared to full fine-tuning, making it feasible to adapt large models on smaller devices.\n",
      "- **Reduced Memory Footprint**: By quantizing the parameters, QLoRA consumes significantly less memory, enabling deployment even on constrained hardware.\n",
      "\n",
      "### Summary\n",
      "In essence, QLoRA is a technique for efficiently adapting large pre-trained neural networks to new tasks. It does this by using a minimal set of parameters (low-rank adaptation) and reducing their size through quantization, which allows for effective deployment of AI models in more resource-constrained environments. \n",
      "\n",
      "Let me know if you need more details or if there's a specific aspect of this you want to explore!\n"
     ]
    }
   ],
   "source": [
    "print(ans.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cf6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
